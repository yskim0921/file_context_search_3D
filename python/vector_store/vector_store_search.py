import os
import sys
import json
import pymysql
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from datetime import datetime

# ================================================================
# 1. ì„¤ì •
# ================================================================

# MySQL ì„¤ì •
DB_CONFIG = {
    'host': 'localhost',
    'user': 'admin',
    'password': '1qazZAQ!',
    'db': 'final',
    'charset': 'utf8mb4'
}

# ì„ë² ë”© ëª¨ë¸
EMBEDDINGS = OllamaEmbeddings(model="exaone3.5:2.4b")

# ================================================================
# 2. MySQLì—ì„œ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
# ================================================================
def get_document_metadata(doc_id):
    """MySQLì—ì„œ doc_idì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë°˜í™˜"""
    try:
        conn = pymysql.connect(**DB_CONFIG)
        with conn.cursor(pymysql.cursors.DictCursor) as cursor:
            cursor.execute("SELECT file_name, file_location, summary, keywords, doc_type FROM documents WHERE id = %s", (doc_id,))
            row = cursor.fetchone()
        conn.close()
        return row if row else {}
    except Exception as e:
        print(f"âš ï¸ MySQL ì¡°íšŒ ì‹¤íŒ¨ (ID: {doc_id}): {e}")
        return {}

# ================================================================
# 3. ìœ ì‚¬ë„ ê²€ìƒ‰ ë° ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
# ================================================================
def search_similar_documents(query: str, chroma_path: str, top_k: int = 5):
    """ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ + ìœ ì‚¬ë„ ê³„ì‚° + í¬ë§· ì¶œë ¥"""
    print(f"\nğŸ” '{query}' ì— ëŒ€í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œì‘...", file=sys.stderr)
    
    try:
        # 1. ChromaDB ë¡œë“œ
        vectorstore = Chroma(persist_directory=chroma_path, embedding_function=EMBEDDINGS)
        
        # 2. ìœ ì‚¬ë„ ê²€ìƒ‰ (score í¬í•¨)
        results = vectorstore.similarity_search_with_score(query, k=top_k)
        
        if not results:
            print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ.", file=sys.stderr)
            return []
        
        # 3. ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ì¶œ â†’ ì •ê·œí™” (0~100%)
        scores = [score for _, score in results]
        min_score = min(scores)
        max_score = max(scores)
        
        print(f"\nğŸ“Š ìœ ì‚¬ë„ ë²”ìœ„: ìµœì†Œ {min_score:.4f} ~ ìµœëŒ€ {max_score:.4f}", file=sys.stderr)
        
        # 4. ê²°ê³¼ ì •ë¦¬
        search_results = []
        for i, (doc, score) in enumerate(results, 1):
            doc_id = doc.metadata.get("id")
            metadata = get_document_metadata(doc_id) if doc_id else {}
            
            # ìœ ì‚¬ë„ ê³„ì‚°: ChromaDBëŠ” ë‚®ì€ ì ìˆ˜ê°€ ë” ìœ ì‚¬í•¨
            # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜: 1 / (1 + distance) í˜•íƒœ
            # ì‹¤ì œ ìœ ì‚¬ë„: scoreê°€ ë‚®ì„ìˆ˜ë¡ (ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡) ìœ ì‚¬ë„ê°€ ë†’ìŒ
            if max_score != min_score:
                # ì •ê·œí™” í›„ ì—­ë³€í™˜: ê°€ì¥ ë‚®ì€ ì ìˆ˜ë¥¼ 100%ë¡œ, ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ 2%ë¡œ
                relevance = (1 - (score - min_score) / (max_score - min_score)) * 98 + 2  # 2~100%
            else:
                relevance = 98.0
            
            # ì¶”ê°€: ì›ë³¸ ê±°ë¦¬ ì ìˆ˜ë„ ì €ì¥ (ë””ë²„ê¹…ìš©)
            distance_score = score
            
            result_item = {
                "rank": i,
                "relevance": round(relevance, 1),  # ìœ ì‚¬ë„ (2~100%)
                "distance": round(distance_score, 4),  # ê±°ë¦¬ ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)
                "file_name": metadata.get("file_name", "unknown"),
                "file_location": metadata.get("file_location", ""),
                "summary": metadata.get("summary", "ìš”ì•½ ì—†ìŒ")[:100] + "...",
                "keywords": metadata.get("keywords", "í‚¤ì›Œë“œ ì—†ìŒ"),
                "doc_type": metadata.get("doc_type", ""),
                "content_preview": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
            }
            search_results.append(result_item)
        
        # 5. ê²°ê³¼ ì¶œë ¥ (stderrë¡œ ë””ë²„ê·¸ ì¶œë ¥)
        print(f"\nâœ… ìƒìœ„ {len(search_results)}ê°œ ê²°ê³¼:", file=sys.stderr)
        print("="*80, file=sys.stderr)
        for res in search_results:
            print(f"\n--- {res['rank']}ìˆœìœ„ ({res['relevance']}%) ---", file=sys.stderr)
            print(f"ğŸ“„ íŒŒì¼ëª…: {res['file_name']}", file=sys.stderr)
            print(f"   ğŸ“ ìœ„ì¹˜: {res['file_location']}", file=sys.stderr)
            print(f"   ğŸ“ ìš”ì•½: {res['summary']}", file=sys.stderr)
            print(f"   ğŸ—ï¸ í‚¤ì›Œë“œ: {res['keywords']}", file=sys.stderr)
            print(f"   ğŸ§© ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {res['content_preview']}", file=sys.stderr)
            print("-" * 80, file=sys.stderr)
        
        return search_results
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
        return []

# ================================================================
# 4. ë©”ì¸ ì‹¤í–‰
# ================================================================
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 3:
        print("âŒ ì‚¬ìš©ë²•: python vector_store_search.py '<ê²€ìƒ‰ì§ˆë¬¸>' '<ë²¡í„°ìŠ¤í† ì–´ê²½ë¡œ>'", file=sys.stderr)
        print(json.dumps([]))
        exit(1)
    
    query = sys.argv[1]
    chroma_path = sys.argv[2]
    
    # ê²€ìƒ‰ ì‹¤í–‰
    results = search_similar_documents(query, chroma_path, top_k=5)
    
    # JSONìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥ (stdout)
    print(json.dumps(results, ensure_ascii=False, indent=2))
    
    if results:
        print(f"\nğŸ‰ ì´ {len(results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ.", file=sys.stderr)
    else:
        print("\nğŸ˜” ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)