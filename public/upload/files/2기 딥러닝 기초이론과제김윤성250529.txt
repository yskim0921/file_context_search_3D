1.	머신러닝의 정의를 서술하시오.

min Cost weight : Cost(오차률)을 최소로하는 방향으로 학습

-------------------------------------------------------------------------------------------------------
2.	머신러닝의 원리를 서술하시오
	1. w(예측값) 초기값 설정
	2. G계산(오차율)
	3. w(기울기-방향) 업데이트 한다 (w - @G)
	
-------------------------------------------------------------------------------------------------------	
3.	머신러닝의 성능 저조 문제와 해결방법을 서술하시오.
	성능저조 문제 :
	언더핏 : 학습 자체가 잘 안되서 시험을 못본것 →  어려운 시험을 단순한 모델이 못 본 상태
	오버핏 : 학습을 잘하는데 시험을 못본것 → 쉬운 시험을 복잡한 모델이 못 본 상태
	
	해결방법 :
	모델성능개선, 서비스 성능개선
	- 데이터 핸들링
	- 모델 핸들링
		- 적절한 모델 선택
		- 모델 구조 수정, 조합
		- 미세조정(경량화-LoRA, QLoRA)
		- RAG(레그)
		- 하이퍼 파라미터 튜닝
-------------------------------------------------------------------------------------------------------
4.	다층퍼셉트론 3가지 관점을 서술하시오.
	1. 비선형적인 문제를 해결하기 위한 비선형 경계선을 찾는 알고리즘
	2. 비선형적인 문제를 선형적인 문제로 변형한 다음, 선형 경계선을 찾는 알고리즘
	3. 입력데이터를 출력데이터로 변형하는 알고리즘
	
-------------------------------------------------------------------------------------------------------	
5.	기울기 소실 문제가 왜 다층퍼셉트론에서 발생하는지, 이를 제프리 힌튼 교수가 어떻게 해결했는지 서술하시오.
	발생원인 : 
	1. 각 층의 sigmoid의 기울기를 각각 계산하여 곱하는 방식의 한계
	2. sigmoid의 기울기는 0~1/4이자 대부분 0에 가까움
	3. 0에 가까운 기울기를 층 수만큼 곱하는 꼴이 되므로, 층이 깊어질수록 기울기는 0에 가까워짐.
		**고찰 : 층이 깊어질수록, 학습이 잘 안됨(언더핏 :학습을 어려워함)
			⇒ 해결하기 어려운 문제: 층을 낮춘다고 해결 되는게 아니기 때문
			
	해결방법 : 
	1. sigmoid를 relu로 교체 : 기울기가 0 또는 1인 비선형 함수로 변경
    **상대적으로 층을 키워도 기울기 소실이 잘 발생하지 않음
	2. w 초기값 설정방법 개선: RBM - 초기값에 애초에 global min 근처에서 생성하는 방법

-------------------------------------------------------------------------------------------------------
6.	아래 조건을 보고, 총 weight의 업데이트 수를 맞추시오.
1) 데이터셋 개수 : 64만개
2) batch size : 64개
3) epoch : 100

64만 / 64개 = 1만개 * 100번 = 100만(weight)

-------------------------------------------------------------------------------------------------------
7.	아래 모듈리스트는 파이토치 기반 모델 학습 시 사용되는 주요 모듈들이다. 각 모듈의 의미를 설명하시오.
  - zero_grad() : 기울기 초기화
        - model(X) : forward 실행 (추론,예측값 설정)
        - cost : 손실함수(오차함수) 선언
        - cost.backward : Gradient 계산
        - optimizer.step :  weight업데이트(오차률재설정)
